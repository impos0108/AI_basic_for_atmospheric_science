{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Deep learning basic with PyTorch__ (@Yeji Choi)\n",
    "### 2021.10.28\n",
    "\n",
    "본자료는 모두를 위한 딥러닝 시즌 2의 자료를 참고하였습니다.\n",
    "https://deeplearningzerotoall.github.io/season2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __파이토치로 선형회귀 문제풀기__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data loader](./data1.png)\n",
    "\n",
    "- 4시간을 공부하면 시험점수는 몇점일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 찾아야 할 식 \n",
    "  \n",
    "__시험점수 = 가중치 * 공부시간 + 편향__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_train, y_train, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형회귀에 필요한 라이브러리 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 가중치와 편향의 초기화\n",
    "\n",
    "학습을 통해 변경될 값임을 선언 - \"requires_grad= True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True) \n",
    "print(W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 가설 (선형관계식) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 비용함수 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2) \n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 경사하강법 구현하기 - torch.optim 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "\n",
    "# 항상함께쓰는 3줄 셋트!\n",
    "optimizer.zero_grad() \n",
    "# 비용 함수를 미분하여 gradient 계산\n",
    "cost.backward() \n",
    "# W와 b를 업데이트\n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __optimizer.zero_grad()를 사용하는 이유__  \n",
    "반복을 통해 가중치와 바이어스가 업데이트 될때 그래디언트가 누적되기 때문에 미분값을 0으로 초기화 해 줘야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 반복학습\n",
    "\n",
    "데이터를 정의하고, 가설을 초기화 하고, optimizer를 정의하는 건 한번만  \n",
    "가설을 통해 예측을 하고, Cost를 계산하고, Optimizer를 이용해서 경사하강법으로 가중치를 업데이트하는건 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.187, b: 0.080 Cost: 18.666666\n",
      "Epoch  100/1000 W: 1.746, b: 0.578 Cost: 0.048171\n",
      "Epoch  200/1000 W: 1.800, b: 0.454 Cost: 0.029767\n",
      "Epoch  300/1000 W: 1.843, b: 0.357 Cost: 0.018394\n",
      "Epoch  400/1000 W: 1.876, b: 0.281 Cost: 0.011366\n",
      "Epoch  500/1000 W: 1.903, b: 0.221 Cost: 0.007024\n",
      "Epoch  600/1000 W: 1.924, b: 0.174 Cost: 0.004340\n",
      "Epoch  700/1000 W: 1.940, b: 0.136 Cost: 0.002682\n",
      "Epoch  800/1000 W: 1.953, b: 0.107 Cost: 0.001657\n",
      "Epoch  900/1000 W: 1.963, b: 0.084 Cost: 0.001024\n",
      "Epoch 1000/1000 W: 1.971, b: 0.066 Cost: 0.000633\n"
     ]
    }
   ],
   "source": [
    "#데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 1000 # 원하는만큼 경사 하강법을 반복\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __다중 선형 회귀 풀어보기__  \n",
    "\n",
    "1. 데이터 정의\n",
    "2. 모델정의\n",
    "3. Optimizer정의\n",
    "4. hypothesis 계산\n",
    "5. Cost 계산\n",
    "6. Gradient descnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data loader](./data2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 w와 편향 b 초기화 - 입력변수가 3개 이므로 가중치도 3개\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
      "Epoch  100/2000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563634\n",
      "Epoch  200/2000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497603\n",
      "Epoch  300/2000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435026\n",
      "Epoch  400/2000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375730\n",
      "Epoch  500/2000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319503\n",
      "Epoch  600/2000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266215\n",
      "Epoch  700/2000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215693\n",
      "Epoch  800/2000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167821\n",
      "Epoch  900/2000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122419\n",
      "Epoch 1000/2000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079375\n",
      "Epoch 1100/2000 w1: 0.722 w2: 0.608 w3: 0.680 b: 0.009 Cost: 1.038569\n",
      "Epoch 1200/2000 w1: 0.727 w2: 0.603 w3: 0.681 b: 0.010 Cost: 0.999893\n",
      "Epoch 1300/2000 w1: 0.731 w2: 0.599 w3: 0.681 b: 0.010 Cost: 0.963217\n",
      "Epoch 1400/2000 w1: 0.735 w2: 0.595 w3: 0.681 b: 0.010 Cost: 0.928421\n",
      "Epoch 1500/2000 w1: 0.739 w2: 0.591 w3: 0.681 b: 0.010 Cost: 0.895448\n",
      "Epoch 1600/2000 w1: 0.743 w2: 0.586 w3: 0.682 b: 0.010 Cost: 0.864175\n",
      "Epoch 1700/2000 w1: 0.746 w2: 0.583 w3: 0.682 b: 0.010 Cost: 0.834503\n",
      "Epoch 1800/2000 w1: 0.750 w2: 0.579 w3: 0.682 b: 0.010 Cost: 0.806368\n",
      "Epoch 1900/2000 w1: 0.754 w2: 0.575 w3: 0.682 b: 0.010 Cost: 0.779692\n",
      "Epoch 2000/2000 w1: 0.757 w2: 0.571 w3: 0.682 b: 0.011 Cost: 0.754390\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬 연산으로 바꿔서 파이토치 구현하기 - 입력 정보의 개수가 많은경우에 matmul로 한번에 계산하기 위해  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n",
      "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch    1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
      "Epoch    2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7861,  95.8280]) Cost: 3069.590820\n",
      "Epoch    3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670288\n",
      "Epoch    4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481873\n",
      "Epoch    5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n",
      "Epoch    6/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687500\n",
      "Epoch    7/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n",
      "Epoch    8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365657\n",
      "Epoch    9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
      "Epoch   10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n",
      "Epoch   11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n",
      "Epoch   12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n",
      "Epoch   13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n",
      "Epoch   14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n",
      "Epoch   15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
      "Epoch   16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
      "Epoch   17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
      "Epoch   18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
      "Epoch   19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n",
      "Epoch   20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"
     ]
    }
   ],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토치 라이브러리로 선형회귀 구현하기 (nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  #loss function을 라이브러리에서 불러올 수 있도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.7542]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2290], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "model = nn.Linear(1,1)\n",
    "\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 37.974918\n",
      "Epoch  100/2000 Cost: 0.060083\n",
      "Epoch  200/2000 Cost: 0.037128\n",
      "Epoch  300/2000 Cost: 0.022943\n",
      "Epoch  400/2000 Cost: 0.014177\n",
      "Epoch  500/2000 Cost: 0.008761\n",
      "Epoch  600/2000 Cost: 0.005414\n",
      "Epoch  700/2000 Cost: 0.003345\n",
      "Epoch  800/2000 Cost: 0.002067\n",
      "Epoch  900/2000 Cost: 0.001277\n",
      "Epoch 1000/2000 Cost: 0.000789\n",
      "Epoch 1100/2000 Cost: 0.000488\n",
      "Epoch 1200/2000 Cost: 0.000301\n",
      "Epoch 1300/2000 Cost: 0.000186\n",
      "Epoch 1400/2000 Cost: 0.000115\n",
      "Epoch 1500/2000 Cost: 0.000071\n",
      "Epoch 1600/2000 Cost: 0.000044\n",
      "Epoch 1700/2000 Cost: 0.000027\n",
      "Epoch 1800/2000 Cost: 0.000017\n",
      "Epoch 1900/2000 Cost: 0.000010\n",
      "Epoch 2000/2000 Cost: 0.000006\n"
     ]
    }
   ],
   "source": [
    "# SGD 생성자에 model.parameters()를 호출하면\n",
    "# nn.Linear 모듈의 학습 가능한 매개변수들이 포함됩니다.\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "\n",
    "nb_epochs = 2000\n",
    "\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward() # backward 연산\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9949]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 4를 선언\n",
    "new_var =  torch.FloatTensor([[4.0]]) \n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "\n",
    "pred_y = model(new_var) # forward 연산\n",
    "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.9971]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0067], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __다중 선형 회귀 구현하기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.3020,  0.4068, -0.0428]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0165], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "model = nn.Linear(3,1)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 27897.162109\n",
      "Epoch  100/2000 Cost: 8.912180\n",
      "Epoch  200/2000 Cost: 8.459203\n",
      "Epoch  300/2000 Cost: 8.030072\n",
      "Epoch  400/2000 Cost: 7.623517\n",
      "Epoch  500/2000 Cost: 7.238436\n",
      "Epoch  600/2000 Cost: 6.873588\n",
      "Epoch  700/2000 Cost: 6.527981\n",
      "Epoch  800/2000 Cost: 6.200536\n",
      "Epoch  900/2000 Cost: 5.890324\n",
      "Epoch 1000/2000 Cost: 5.596471\n",
      "Epoch 1100/2000 Cost: 5.318006\n",
      "Epoch 1200/2000 Cost: 5.054259\n",
      "Epoch 1300/2000 Cost: 4.804394\n",
      "Epoch 1400/2000 Cost: 4.567622\n",
      "Epoch 1500/2000 Cost: 4.343341\n",
      "Epoch 1600/2000 Cost: 4.130832\n",
      "Epoch 1700/2000 Cost: 3.929518\n",
      "Epoch 1800/2000 Cost: 3.738780\n",
      "Epoch 1900/2000 Cost: 3.558057\n",
      "Epoch 2000/2000 Cost: 3.386846\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.6848]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "\n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5657, 0.7942, 0.6510]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0279], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __모델을 클래스로 구현하기__\n",
    "\n",
    "1. 단순 선형회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module): # torch.nn.Module을 상속받는 파이썬 클래스\n",
    "    def __init__(self): #\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1) # 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 18.729185\n",
      "Epoch  100/2000 Cost: 0.176202\n",
      "Epoch  200/2000 Cost: 0.108882\n",
      "Epoch  300/2000 Cost: 0.067283\n",
      "Epoch  400/2000 Cost: 0.041577\n",
      "Epoch  500/2000 Cost: 0.025692\n",
      "Epoch  600/2000 Cost: 0.015876\n",
      "Epoch  700/2000 Cost: 0.009810\n",
      "Epoch  800/2000 Cost: 0.006062\n",
      "Epoch  900/2000 Cost: 0.003746\n",
      "Epoch 1000/2000 Cost: 0.002315\n",
      "Epoch 1100/2000 Cost: 0.001430\n",
      "Epoch 1200/2000 Cost: 0.000884\n",
      "Epoch 1300/2000 Cost: 0.000546\n",
      "Epoch 1400/2000 Cost: 0.000338\n",
      "Epoch 1500/2000 Cost: 0.000209\n",
      "Epoch 1600/2000 Cost: 0.000129\n",
      "Epoch 1700/2000 Cost: 0.000080\n",
      "Epoch 1800/2000 Cost: 0.000049\n",
      "Epoch 1900/2000 Cost: 0.000030\n",
      "Epoch 2000/2000 Cost: 0.000019\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) \n",
    "\n",
    "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward() # backward 연산\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 다중 선형회귀 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1) # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 5338.200195\n",
      "Epoch  100/2000 Cost: 3.243483\n",
      "Epoch  200/2000 Cost: 3.097303\n",
      "Epoch  300/2000 Cost: 2.958745\n",
      "Epoch  400/2000 Cost: 2.827426\n",
      "Epoch  500/2000 Cost: 2.702963\n",
      "Epoch  600/2000 Cost: 2.584976\n",
      "Epoch  700/2000 Cost: 2.473135\n",
      "Epoch  800/2000 Cost: 2.367105\n",
      "Epoch  900/2000 Cost: 2.266615\n",
      "Epoch 1000/2000 Cost: 2.171340\n",
      "Epoch 1100/2000 Cost: 2.080991\n",
      "Epoch 1200/2000 Cost: 1.995371\n",
      "Epoch 1300/2000 Cost: 1.914169\n",
      "Epoch 1400/2000 Cost: 1.837186\n",
      "Epoch 1500/2000 Cost: 1.764188\n",
      "Epoch 1600/2000 Cost: 1.694955\n",
      "Epoch 1700/2000 Cost: 1.629292\n",
      "Epoch 1800/2000 Cost: 1.567043\n",
      "Epoch 1900/2000 Cost: 1.507997\n",
      "Epoch 2000/2000 Cost: 1.451980\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 미니배치 이용하기: 대부분의 데이터는 적어도 수십만개 \n",
    "\n",
    "엄청나게 많은 양의 데이터를 한번에 학습할 수 없다. - 너무 느리고, 하드웨어적으로도 불가능  \n",
    "일부데이터로 학습하는 방법이 미니배치를 이용하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 32915.390625\n",
      "Epoch    0/20 Batch 2/3 Cost: 24823.759766\n",
      "Epoch    0/20 Batch 3/3 Cost: 4877.746582\n",
      "Epoch    1/20 Batch 1/3 Cost: 1147.888062\n",
      "Epoch    1/20 Batch 2/3 Cost: 391.019348\n",
      "Epoch    1/20 Batch 3/3 Cost: 137.026001\n",
      "Epoch    2/20 Batch 1/3 Cost: 27.952017\n",
      "Epoch    2/20 Batch 2/3 Cost: 23.567020\n",
      "Epoch    2/20 Batch 3/3 Cost: 2.381600\n",
      "Epoch    3/20 Batch 1/3 Cost: 2.465296\n",
      "Epoch    3/20 Batch 2/3 Cost: 2.173973\n",
      "Epoch    3/20 Batch 3/3 Cost: 8.966888\n",
      "Epoch    4/20 Batch 1/3 Cost: 3.889177\n",
      "Epoch    4/20 Batch 2/3 Cost: 0.306075\n",
      "Epoch    4/20 Batch 3/3 Cost: 5.879900\n",
      "Epoch    5/20 Batch 1/3 Cost: 0.075669\n",
      "Epoch    5/20 Batch 2/3 Cost: 2.026061\n",
      "Epoch    5/20 Batch 3/3 Cost: 11.111688\n",
      "Epoch    6/20 Batch 1/3 Cost: 2.214596\n",
      "Epoch    6/20 Batch 2/3 Cost: 5.513571\n",
      "Epoch    6/20 Batch 3/3 Cost: 0.015797\n",
      "Epoch    7/20 Batch 1/3 Cost: 5.501945\n",
      "Epoch    7/20 Batch 2/3 Cost: 0.624093\n",
      "Epoch    7/20 Batch 3/3 Cost: 0.300710\n",
      "Epoch    8/20 Batch 1/3 Cost: 3.469089\n",
      "Epoch    8/20 Batch 2/3 Cost: 4.832385\n",
      "Epoch    8/20 Batch 3/3 Cost: 0.066059\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.287600\n",
      "Epoch    9/20 Batch 2/3 Cost: 5.979525\n",
      "Epoch    9/20 Batch 3/3 Cost: 0.230498\n",
      "Epoch   10/20 Batch 1/3 Cost: 2.577010\n",
      "Epoch   10/20 Batch 2/3 Cost: 5.256508\n",
      "Epoch   10/20 Batch 3/3 Cost: 0.001092\n",
      "Epoch   11/20 Batch 1/3 Cost: 0.688679\n",
      "Epoch   11/20 Batch 2/3 Cost: 3.426022\n",
      "Epoch   11/20 Batch 3/3 Cost: 7.932660\n",
      "Epoch   12/20 Batch 1/3 Cost: 0.217774\n",
      "Epoch   12/20 Batch 2/3 Cost: 3.866865\n",
      "Epoch   12/20 Batch 3/3 Cost: 6.689282\n",
      "Epoch   13/20 Batch 1/3 Cost: 5.256902\n",
      "Epoch   13/20 Batch 2/3 Cost: 3.822434\n",
      "Epoch   13/20 Batch 3/3 Cost: 0.295130\n",
      "Epoch   14/20 Batch 1/3 Cost: 0.348518\n",
      "Epoch   14/20 Batch 2/3 Cost: 2.008006\n",
      "Epoch   14/20 Batch 3/3 Cost: 10.849473\n",
      "Epoch   15/20 Batch 1/3 Cost: 1.230628\n",
      "Epoch   15/20 Batch 2/3 Cost: 2.596580\n",
      "Epoch   15/20 Batch 3/3 Cost: 8.258608\n",
      "Epoch   16/20 Batch 1/3 Cost: 6.081085\n",
      "Epoch   16/20 Batch 2/3 Cost: 0.408566\n",
      "Epoch   16/20 Batch 3/3 Cost: 0.252555\n",
      "Epoch   17/20 Batch 1/3 Cost: 5.667434\n",
      "Epoch   17/20 Batch 2/3 Cost: 0.463203\n",
      "Epoch   17/20 Batch 3/3 Cost: 0.186327\n",
      "Epoch   18/20 Batch 1/3 Cost: 0.291313\n",
      "Epoch   18/20 Batch 2/3 Cost: 3.610321\n",
      "Epoch   18/20 Batch 3/3 Cost: 7.040432\n",
      "Epoch   19/20 Batch 1/3 Cost: 2.084352\n",
      "Epoch   19/20 Batch 2/3 Cost: 5.233190\n",
      "Epoch   19/20 Batch 3/3 Cost: 0.945971\n",
      "Epoch   20/20 Batch 1/3 Cost: 3.519374\n",
      "Epoch   20/20 Batch 2/3 Cost: 3.570398\n",
      "Epoch   20/20 Batch 3/3 Cost: 0.506778\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    # print(batch_idx)\n",
    "    # print(samples)\n",
    "    x_train, y_train = samples\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.5352]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __사용자 데이터 활용하기__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용자가 가지고 있는 데이터셋을 이용하는 방법    \n",
    "\n",
    "![data loader](./dataloader.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형회귀 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 상속\n",
    "class CustomDataset(Dataset): \n",
    "  def __init__(self):\n",
    "    self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "    self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx): \n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 54914.480469\n",
      "Epoch    0/20 Batch 2/3 Cost: 13855.873047\n",
      "Epoch    0/20 Batch 3/3 Cost: 6956.426758\n",
      "Epoch    1/20 Batch 1/3 Cost: 1240.926147\n",
      "Epoch    1/20 Batch 2/3 Cost: 641.935608\n",
      "Epoch    1/20 Batch 3/3 Cost: 46.455490\n",
      "Epoch    2/20 Batch 1/3 Cost: 91.712265\n",
      "Epoch    2/20 Batch 2/3 Cost: 4.434297\n",
      "Epoch    2/20 Batch 3/3 Cost: 1.488589\n",
      "Epoch    3/20 Batch 1/3 Cost: 10.917598\n",
      "Epoch    3/20 Batch 2/3 Cost: 5.173336\n",
      "Epoch    3/20 Batch 3/3 Cost: 3.633673\n",
      "Epoch    4/20 Batch 1/3 Cost: 7.710946\n",
      "Epoch    4/20 Batch 2/3 Cost: 4.156493\n",
      "Epoch    4/20 Batch 3/3 Cost: 2.055585\n",
      "Epoch    5/20 Batch 1/3 Cost: 5.546842\n",
      "Epoch    5/20 Batch 2/3 Cost: 5.594285\n",
      "Epoch    5/20 Batch 3/3 Cost: 1.234643\n",
      "Epoch    6/20 Batch 1/3 Cost: 6.970074\n",
      "Epoch    6/20 Batch 2/3 Cost: 3.855728\n",
      "Epoch    6/20 Batch 3/3 Cost: 1.339809\n",
      "Epoch    7/20 Batch 1/3 Cost: 6.938311\n",
      "Epoch    7/20 Batch 2/3 Cost: 3.459246\n",
      "Epoch    7/20 Batch 3/3 Cost: 2.516360\n",
      "Epoch    8/20 Batch 1/3 Cost: 5.393038\n",
      "Epoch    8/20 Batch 2/3 Cost: 1.056504\n",
      "Epoch    8/20 Batch 3/3 Cost: 12.192709\n",
      "Epoch    9/20 Batch 1/3 Cost: 2.832443\n",
      "Epoch    9/20 Batch 2/3 Cost: 6.394364\n",
      "Epoch    9/20 Batch 3/3 Cost: 3.649863\n",
      "Epoch   10/20 Batch 1/3 Cost: 0.654283\n",
      "Epoch   10/20 Batch 2/3 Cost: 5.776013\n",
      "Epoch   10/20 Batch 3/3 Cost: 10.201247\n",
      "Epoch   11/20 Batch 1/3 Cost: 6.501355\n",
      "Epoch   11/20 Batch 2/3 Cost: 2.856537\n",
      "Epoch   11/20 Batch 3/3 Cost: 4.062252\n",
      "Epoch   12/20 Batch 1/3 Cost: 5.700433\n",
      "Epoch   12/20 Batch 2/3 Cost: 3.136978\n",
      "Epoch   12/20 Batch 3/3 Cost: 5.326013\n",
      "Epoch   13/20 Batch 1/3 Cost: 4.395747\n",
      "Epoch   13/20 Batch 2/3 Cost: 3.046005\n",
      "Epoch   13/20 Batch 3/3 Cost: 12.469296\n",
      "Epoch   14/20 Batch 1/3 Cost: 3.242088\n",
      "Epoch   14/20 Batch 2/3 Cost: 8.591545\n",
      "Epoch   14/20 Batch 3/3 Cost: 7.957778\n",
      "Epoch   15/20 Batch 1/3 Cost: 2.338494\n",
      "Epoch   15/20 Batch 2/3 Cost: 11.709427\n",
      "Epoch   15/20 Batch 3/3 Cost: 2.703228\n",
      "Epoch   16/20 Batch 1/3 Cost: 5.595684\n",
      "Epoch   16/20 Batch 2/3 Cost: 2.715334\n",
      "Epoch   16/20 Batch 3/3 Cost: 8.777365\n",
      "Epoch   17/20 Batch 1/3 Cost: 6.027912\n",
      "Epoch   17/20 Batch 2/3 Cost: 3.567591\n",
      "Epoch   17/20 Batch 3/3 Cost: 7.896172\n",
      "Epoch   18/20 Batch 1/3 Cost: 6.099917\n",
      "Epoch   18/20 Batch 2/3 Cost: 7.049979\n",
      "Epoch   18/20 Batch 3/3 Cost: 8.775014\n",
      "Epoch   19/20 Batch 1/3 Cost: 3.669638\n",
      "Epoch   19/20 Batch 2/3 Cost: 3.086262\n",
      "Epoch   19/20 Batch 3/3 Cost: 11.493234\n",
      "Epoch   20/20 Batch 1/3 Cost: 2.800276\n",
      "Epoch   20/20 Batch 2/3 Cost: 5.196641\n",
      "Epoch   20/20 Batch 3/3 Cost: 10.450229\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# shuffle=True는 epoch마다 데이터를 섞는 것을 말한다.\n",
    "\n",
    "model = torch.nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
    "\n",
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader): # enumerate는 인덱스와 데이터를 만드는 함수\n",
    "    # print(batch_idx)\n",
    "    # print(samples)\n",
    "    x_train, y_train = samples\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),  # len(dataloader): 한 에포크당 minibatch개수\n",
    "        cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[154.7225]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __로지스틱 회귀__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data loader](./lo_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data loader](./reminder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시험성적에 따른 합격, 불합격 데이터\n",
    "\n",
    "![binary data](./binary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b89ea14b4d0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXpUlEQVR4nO3de5CV9X3H8fc3u6LxwiWyQWVBEJFIDDdXRLyACgrKJZlJZ5BYU6cpcSK1aaZTbZO2mWQ6k3SamUwGlVJrTZsYprW2z+FSEDDiZeWyqF3kJrugsKKwK7oqoFz22z/2HD0czu4e2Ofsc87zfF4zO3ueC+d8fzyzn3nO7zzP95i7IyIi5e8LURcgIiLhUKCLiMSEAl1EJCYU6CIiMaFAFxGJicqoXrh///4+ZMiQqF5eRKQsbdq0qcXdq/JtiyzQhwwZQl1dXVQvLyJSlszsrY62acpFRCQmFOgiIjGhQBcRiQkFuohITCjQRURiostAN7PHzeyAmb3ewXYzs1+ZWYOZ1ZvZuPDLFImvhWsbqW1sOWldbWMLC9c2RlRR8WnM7cIecyFn6E8A0zrZPh0Ynv6ZBzza/bJEkmNUdR/mP/nqZ3/stY0tzH/yVUZV94m4suLRmIszZiukfa6ZDQGWuvtVebb9E/Ccu/8uvbwDmOzu73T2nDU1Na7r0EXa1Ta28N1fb2Do8b3saBvApMoGLvrCh1GXVVTvtvVm7fHLGfGF/Ykb85QhZ/NycyUL5o5l4rD+p/UcZrbJ3WvybQvjxqKBwN6s5ab0ulMC3czm0X4Wz+DBg0N4aZF4mDisP5+8vor6K6bQWruYx178bdQl9Yg+N3yLTyfOSdyYlzGHB24ZfNph3pUwPhS1POvynva7+yJ3r3H3mqqqvHeuiiTSUy/U80n1NVx7/kGGTr2HF3ceoK2tLdY/L+48wNCp9/DALZcncsy/Wb/nlDn17goj0JuAQVnL1cC+EJ5XJBFqG1v40fLdNAc/4+d338iCuWNPmmuNo8z88YK5Y/nBbSM05pCEEegp4J701S4TgNau5s9F5HP1Ta30ef0pRvQ1hgwZwsRh/Vkwdyz1Ta1Rl1Y09U2tJ80fa8zh6PJDUTP7HTAZ6A/sB/4OOAvA3ReamQELaL8S5jBwr7t3+WmnPhQVadfS0sKAAQP44Q9/yE9+8pOoy5ES160PRd39ri62O3D/GdYmknjLli2jra2NWbNmRV2KlDndKSoSsSAIGDhwIFdffXXUpUiZU6CLROiTTz5h5cqVzJo1i/bZS5Ezp0AXidCaNWs4fPgws2fPjroUiQEFukiEgiDgggsuYPLkyVGXIjGgQBeJSFtbG0uWLGH69OmcffbZUZcjMaBAF4nIhg0bePfdd3V1i4RGgS4SkSAIqKio4I477oi6FIkJBbpIRFKpFJMmTaJfv35RlyIxoUAXiUBDQwNbt27V1S0SKgW6SASCIABQoEuoFOgiEQiCgNGjR3PppZdGXYrEiAJdpIe1tLTw0ksv6eoWCZ0CXaSHLV26lLa2Nk23SOgU6CI9LJVKUV1dzbhx46IuRWJGgS7Sg44cOaJmXFI0CnSRHqRmXFJMCnSRHqRmXFJMCnSRHpLdjKtXr15RlyMxpEAX6SHr169n//79mm6RolGgi/SQVCpFZWWlmnFJ0SjQRXpIEARMmjSJvn37Rl2KxJQCXaQH7Ny5k23btmm6RYpKgS7SAzLNuHS7vxSTAl2kBwRBwJgxY9SMS4pKgS5SZM3NzdTW1ursXIpOgS5SZMuWLVMzLukRCnSRIguCgEGDBjF27NioS5GYU6CLFNGRI0d45pln1IxLeoQCXaSIVq9erWZc0mMU6CJFFAQBvXv3ZtKkSVGXIgmgQBcpkhMnTqgZl/SoggLdzKaZ2Q4zazCzh/Js72NmS8zs/8xsi5ndG36pIuVlw4YNHDhwQNMt0mO6DHQzqwAeBqYDI4G7zGxkzm73A1vdfTQwGfiFmemURBItCAIqKyuZPn161KVIQhRyhj4eaHD3Xe5+FFgM5J5yOHCBtX+Mfz5wEDgeaqUiZSYIAiZPnqxmXNJjCgn0gcDerOWm9LpsC4ArgX3AZuDP3L0t94nMbJ6Z1ZlZXXNz8xmWLFL63njjDbZv367pFulRhQR6votnPWf5duA14BJgDLDAzHqf8o/cF7l7jbvXVFVVnWapIuVDzbgkCoUEehMwKGu5mvYz8Wz3Ak97uwZgN/CVcEoUKT+ZZlyDBw+OuhRJkEICfSMw3MyGpj/onAOkcvbZA9wKYGYDgBHArjALFSkXmWZcmm6RnlbZ1Q7uftzM5gMrgQrgcXffYmb3pbcvBH4KPGFmm2mfonnQ3VuKWLdIyVq6dCnurkCXHtdloAO4+3Jgec66hVmP9wG3hVuaSHkKgoDBgwczZsyYqEuRhNGdoiIhOnz4sJpxSWQU6CIhWr16NUeOHNF0i0RCgS4SokwzrptuuinqUiSBFOgiIck047rjjjvUjEsioUAXCcn69etpbm7WdItERoEuEpIgCDjrrLPUjEsio0AXCUmmGVefPn2iLkUSSoEuEoIdO3awY8cOTbdIpBToIiHINOOaOXNmxJVIkinQRUKQSqUYO3asmnFJpBToIt104MABNeOSkqBAF+kmNeOSUqFAF+mmIAi49NJLGT16dNSlSMIp0EW64fDhw6xatUrNuKQkKNBFumHVqlUcOXJEXzUnJUGBLtINqVSKPn36MGnSpKhLEVGgi5yp7GZcZ511VtTliCjQRc7UunXr1IxLSooCXeQMqRmXlBoFusgZCoKAm2++md69e0ddigigQBc5I9u3b+eNN97Q1S1SUhToImcglUoBKNClpCjQRc5AEASMGzeOQYMGRV2KyGcU6CKnaf/+/bz88su6ukVKjgJd5DSpGZeUKgW6yGnKNOMaNWpU1KWInESBLnIaDh06pGZcUrIU6CKnYfXq1XzyySeabpGSpEAXOQ1BENC3b19uuummqEsROYUCXaRAJ06cYOnSpWrGJSWroEA3s2lmtsPMGszsoQ72mWxmr5nZFjNbG26ZItF7+eWX1YxLSlplVzuYWQXwMDAVaAI2mlnK3bdm7dMXeASY5u57zOzLRapXJDKZZlzTpk2LuhSRvAo5Qx8PNLj7Lnc/CiwGck9R5gJPu/seAHc/EG6ZItFydzXjkpJXSKAPBPZmLTel12W7AuhnZs+Z2SYzuyffE5nZPDOrM7O65ubmM6tYJAI7duxg586dmm6RklZIoOe72NZzliuBq4E7gduBvzGzK075R+6L3L3G3WuqqqpOu1iRqARBAKgZl5S2LufQaT8jz+5AVA3sy7NPi7sfAg6Z2fPAaOCNUKoUiVgQBFx99dVUV1dHXYpIhwo5Q98IDDezoWbWC5gDpHL2CYAbzazSzM4FrgW2hVuqSDT279/PunXrNN0iJa/LM3R3P25m84GVQAXwuLtvMbP70tsXuvs2M1sB1ANtwGPu/noxCxfpKUuWLFEzLikL5p47Hd4zampqvK6uLpLXFjkdM2fOZPPmzezevVv9WyRyZrbJ3WvybdOdoiKdOHToEKtXr2b27NkKcyl5CnSRTqxatUrNuKRsKNBFOpFpxnXjjTdGXYpIlxToIh3INOO688471YxLyoICXaQDtbW1tLS0aLpFyoYCXaQDmWZct99+e9SliBREgS6SR6YZ1y233KJmXFI2FOgieWzfvp2GhgZNt0hZUaCL5KFmXFKOFOgieQRBQE1NDQMH5naKFildCnSRHO+++y7r16/XdIuUHQW6SI5MMy5Nt0i5UaCL5AiCgCFDhvC1r30t6lJETosCXSSLmnFJOVOgi2R55pln+PTTTzV/LmVJgS6SJQgC+vXrp2ZcUpYU6CJpx48f/6wZV2VlIV+3K1JaFOgiabW1tbz33nuabpGypUAXSQuCgF69eqkZl5QtBboIJzfjuuCCC6IuR+SMKNBFgG3bttHY2KjpFilrCnQR1IxL4kGBLkJ7oF9zzTVccsklUZcicsYU6JJ477zzjppxSSwo0CXxlixZAmi6RcqfAl0SL5VKMXToUK666qqoSxHpFgW6JNrHH3+sZlwSGwp0STQ145I4UaBLogVBwJe+9CVuuOGGqEsR6TYFuiSWmnFJ3CjQJbFeeuklDh48qKtbJDYKCnQzm2ZmO8yswcwe6mS/a8zshJl9M7wSRYojlUqpGZfESpeBbmYVwMPAdGAkcJeZjexgv58DK8MuUiRsmWZct956q5pxSWwUcoY+Hmhw913ufhRYDOS7JOBPgf8CDoRYn0hRbN26Vc24JHYKCfSBwN6s5ab0us+Y2UDgG8DCzp7IzOaZWZ2Z1TU3N59urSKhyTTjmjlzZsSViISnkEDPd7eF5yz/EnjQ3U909kTuvsjda9y9pqqqqsASRcIXBAHjx49XMy6JlUICvQkYlLVcDezL2acGWGxmbwLfBB4xs6+HUaBI2Pbt28eGDRt0dYvETiEX324EhpvZUOBtYA4wN3sHdx+aeWxmTwBL3f1/witTJDxLly4F0Py5xE6Xge7ux81sPu1Xr1QAj7v7FjO7L72903lzkVITBAGXXXYZX/3qV6MuRSRUBd0e5+7LgeU56/IGubv/UffLEimOjz/+mDVr1vC9731PzbgkdnSnqCTKypUr1YxLYkuBLomSacZ1/fXXR12KSOgU6JIYx48fZ9myZWrGJbGlQJfEyDTj0nSLxJUCXRIjCALOPvtsNeOS2FKgSyJkN+M6//zzoy5HpCgU6JIIW7ZsYdeuXZpukVhToEsiqBmXJIECXRIh04zr4osvjroUkaJRoEvs7du3j40bN2q6RWJPgS6xt2TJEkDNuCT+FOgSe0EQMGzYMEaOPOWbE0ViRYEusfbRRx+xZs0aZs+erWZcEnsKdIm1lStXcvToUU23SCIo0CXWMs24Jk6cGHUpIkWnQJfYyjTjmjFjhppxSSIo0CW2XnzxRd5//31Nt0hiKNAltjLNuG677baoSxHpEQp0iaVMM64pU6aoGZckhgJdYun1119n9+7dmm6RRFGgSyxlmnHNmDEj4kpEeo4CXWIplUpx7bXXqhmXJIoCXWJHzbgkqRToEjupVApQMy5JHgW6xE4QBFx++eVceeWVUZci0qMU6BIrH330Ec8++6yacUkiKdAlVlasWMHRo0eZNWtW1KWI9DgFusRKKpXiwgsvVDMuSSQFusTGsWPH1IxLEk2BLrGhZlySdAUFuplNM7MdZtZgZg/l2f4tM6tP/9Sa2ejwSxXpXBAEnHPOOWrGJYnVZaCbWQXwMDAdGAncZWa5X864G5jk7qOAnwKLwi5UpDPZzbjOO++8qMsRiUQhZ+jjgQZ33+XuR4HFwEnvad291t3fTy+uA6rDLVOkc5s3b+bNN9/U1S2SaIUE+kBgb9ZyU3pdR/4Y+N98G8xsnpnVmVldc3Nz4VWKdCEIAsyMmTNnRl2KSGQKCfR8d2d43h3NbqY90B/Mt93dF7l7jbvXVFVVFV6lSBcyzbguuuiiqEsRiUwhgd4EDMpargb25e5kZqOAx4DZ7v5eOOWJdO3tt9+mrq5OV7dI4hUS6BuB4WY21Mx6AXOAVPYOZjYYeBr4Q3d/I/wyRTqmZlwi7bq8+8Ldj5vZfGAlUAE87u5bzOy+9PaFwN8CFwKPpPtnHHf3muKVLfK5IAgYPnw4X/nKV6IuRSRSBd1O5+7LgeU56xZmPf4O8J1wSxPp2ocffsizzz7LAw88oGZckni6U1TK2ooVKzh27JimW0RQoEuZS6VS9O/fX824RFCgSxnLbsZVUVERdTkikVOgS9l64YUX+OCDDzTdIpKmQJeylWnGNXXq1KhLESkJCnQpS2rGJXIqBbqUpfr6et566y1Nt4hkUaBLWUqlUmrGJZJDgS5lKQgCJkyYwIABA6IuRaRkKNCl7DQ1NbFp0yZNt4jkUKBL2VEzLpH8FOhSdoIg4IorrlAzLpEcCnQpK62trfz+97/XV82J5KFAl7KycuVKNeMS6YACXcpKEARUVVVx3XXXRV2KSMlRoEvZOHbsGMuXL1czLpEOKNClbDz//PNqxiXSCQW6lA014xLpnAJdykKmGdfUqVM599xzoy5HpCQp0KUs1NfXs2fPHk23iHRCgS5lIQgCzIwZM2ZEXYpIyVKgS1kIgoDrrrtOzbhEOqFAl5K3d+9eXnnlFU23iHRBgS4lT824RAqjQJeSl2nGNWLEiKhLESlpCnQpaa2trTz33HM6OxcpgAJdStqKFSvUjEukQAp0KWmZZlwTJkyIuhSRkqdAl5KVacY1c+ZMNeMSKYACXUrW2rVraW1t1XSLSIEU6FKygiDgi1/8IlOmTIm6FJGyUFCgm9k0M9thZg1m9lCe7WZmv0pvrzezcWEXunBtI7WNLSetq21sYeHaxrBfqmQkeczuTiqVYurUqbz2zuFYj1kkLF0GuplVAA8D04GRwF1mNjJnt+nA8PTPPODRkOtkVHUf5j/56mcBV9vYwvwnX2VUdZ+wX6pkJHnMv3lmA3v27GHU1G/GfswiYaksYJ/xQIO77wIws8XAbGBr1j6zgX9zdwfWmVlfM7vY3d8Jq9CJw/qzYO5Y5j2xnk+3rObYpRM4Z9Nv+ZPF8T5zO3HhMOYe/BZnvbUuUWP+0Xtz6Xvj3Sx578s8cvdYJg7rH3VZIiWvkEAfCOzNWm4Cri1gn4HASYFuZvNoP4Nn8ODBp1srE4f157ah5/D0sSlccvA1Bg44GwbkvlmIn7cPNbDvioSN+XAjNnEO91w3RGEuUqBCAt3yrPMz2Ad3XwQsAqipqTlle1dqG1t47u02Hrjlcn6zvhd//uB3Y//HnplmeeDawQkd8x4mDLsw9mMWCUMhH4o2AYOylquBfWewT7dk/sgXzB3LD24bwYK5Y0+aX44jjTkZYxYJSyGBvhEYbmZDzawXMAdI5eyTAu5JX+0yAWgNc/4coL6plQVzP59Lzcyp1ze1hvkyJUVjTsaYRcJi7Z9jdrGT2R3AL4EK4HF3/3szuw/A3ReamQELgGnAYeBed6/r7Dlramq8rq7TXUREJIeZbXL3mnzbCplDx92XA8tz1i3MeuzA/d0pUkREukd3ioqIxIQCXUQkJhToIiIxoUAXEYmJgq5yKcoLmzUDb53hP+8PJO3CZI05GTTmZOjOmC9196p8GyIL9O4ws7qOLtuJK405GTTmZCjWmDXlIiISEwp0EZGYKNdAXxR1ARHQmJNBY06Gooy5LOfQRUTkVOV6hi4iIjkU6CIiMVEWgW5mFWb2qpktTS//2MzeNrPX0j93RF1j2MzsTTPbnB5fXXrdl8xslZntTP/uF3WdYepgzLE91umvanzKzLab2TYzuy4BxzjfmON8jEdkjes1M/vQzL5frONcFnPoZvYDoAbo7e4zzOzHwMfu/o/RVlY8ZvYmUOPuLVnr/gE46O4/M7OHgH7u/mBUNYatgzH/mJgeazP7NfCCuz+W/q6Bc4G/Jt7HON+Yv09Mj3E2M6sA3qb9KzzvpwjHueTP0M2sGrgTeCzqWkrAbODX6ce/Br4eXSnSHWbWG7gJ+BcAdz/q7h8Q42PcyZiT4lag0d3fokjHueQDnfYv1vhLoC1n/Xwzqzezx+P2tjTNgWfMbFP6y7UBBmS+CSr9+8uRVVcc+cYM8TzWlwHNwL+mpxMfM7PziPcx7mjMEM9jnGsO8Lv046Ic55IOdDObARxw9005mx4FhgFjgHeAX/RwaT3hencfB0wH7jezm6IuqAfkG3Ncj3UlMA541N3HAoeAh6Itqeg6GnNcj/Fn0tNLs4D/LObrlHSgA9cDs9Jzq4uBW8zsN+6+391PuHsb8M/A+CiLLAZ335f+fQD4b9rHuN/MLgZI/z4QXYXhyzfmGB/rJqDJ3denl5+iPezifIzzjjnGxzjbdOAVd9+fXi7KcS7pQHf3v3L3ancfQvvblWfd/e7Mf0TaN4DXIymwSMzsPDO7IPMYuI32MaaAb6d3+zYQRFNh+Doac1yPtbu/C+w1sxHpVbcCW4nxMe5ozHE9xjnu4vPpFijScS6Lq1wAzGwy8Bfpq1z+nfa3Zw68CXw3Mx8VB2Z2Ge1nqND+NvXJ9BdzXwj8BzAY2AP8gbsfjKjMUHUy5tgeazMbQ/uH/b2AXcC9tJ9kxfIYQ4dj/hUxPcYAZnYusBe4zN1b0+uK8rdcNoEuIiKdK+kpFxERKZwCXUQkJhToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISE/8PXv9SrRTmqi8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=[45,50,55,60,65,70]\n",
    "y=[0,0,0,1,1,1]\n",
    "\n",
    "plt.plot(x,y,color='black')\n",
    "plt.plot(x,y,'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시그모이드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x): # 시그모이드 함수 정의\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y, 'g')\n",
    "plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가\n",
    "plt.title('Sigmoid Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "W = torch.zeros((2, 1), requires_grad=True) # 크기는 2 x 1\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계산 식으로 적어도 되지만, 토치 라이브러리를 이용해서 시그모이드 함수 구현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binary Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cle_loss](./cat_cle_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses=-(y_train[0] * torch.log(hypothesis[0]) + \n",
    "  (1 - y_train[0]) * torch.log(1 - hypothesis[0]))\n",
    "\n",
    "cost=losses.mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계산식으로 적어도 되지만, 토치 라이브러리를 이용해서 크로스엔트로피 구현가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.693147\n",
      "Epoch  100/1000 Cost: 0.134722\n",
      "Epoch  200/1000 Cost: 0.080643\n",
      "Epoch  300/1000 Cost: 0.057900\n",
      "Epoch  400/1000 Cost: 0.045300\n",
      "Epoch  500/1000 Cost: 0.037261\n",
      "Epoch  600/1000 Cost: 0.031673\n",
      "Epoch  700/1000 Cost: 0.027556\n",
      "Epoch  800/1000 Cost: 0.024394\n",
      "Epoch  900/1000 Cost: 0.021888\n",
      "Epoch 1000/1000 Cost: 0.019852\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산\n",
    "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "    cost = -(y_train * torch.log(hypothesis) + \n",
    "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 크로스엔트로피 라이브러리 이용한 결과와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.693147\n",
      "Epoch  100/1000 Cost: 0.134722\n",
      "Epoch  200/1000 Cost: 0.080643\n",
      "Epoch  300/1000 Cost: 0.057900\n",
      "Epoch  400/1000 Cost: 0.045300\n",
      "Epoch  500/1000 Cost: 0.037261\n",
      "Epoch  600/1000 Cost: 0.031673\n",
      "Epoch  700/1000 Cost: 0.027556\n",
      "Epoch  800/1000 Cost: 0.024394\n",
      "Epoch  900/1000 Cost: 0.021888\n",
      "Epoch 1000/1000 Cost: 0.019852\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((2, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산\n",
    "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "    cost =F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 잘 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7648e-04],\n",
      "        [3.1608e-02],\n",
      "        [3.8977e-02],\n",
      "        [9.5622e-01],\n",
      "        [9.9823e-01],\n",
      "        [9.9969e-01]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True],\n",
      "        [ True]])\n"
     ]
    }
   ],
   "source": [
    "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습된 파라미터 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2530],\n",
      "        [1.5179]], requires_grad=True)\n",
      "tensor([-14.4819], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체를 다 파이토치 라이브러리로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1390],\n",
       "        [0.0638],\n",
       "        [0.0738],\n",
       "        [0.0234],\n",
       "        [0.0140],\n",
       "        [0.0117]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "model = nn.Sequential(\n",
    "   nn.Linear(2, 1), # input_dim = 2, output_dim = 1\n",
    "   nn.Sigmoid() # 출력은 시그모이드 함수를 거친다\n",
    ")\n",
    "\n",
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 2.127849 Accuracy 50.00%\n",
      "Epoch   10/100 Cost: 0.479633 Accuracy 66.67%\n",
      "Epoch   20/100 Cost: 0.410227 Accuracy 83.33%\n",
      "Epoch   30/100 Cost: 0.347159 Accuracy 83.33%\n",
      "Epoch   40/100 Cost: 0.293602 Accuracy 83.33%\n",
      "Epoch   50/100 Cost: 0.245430 Accuracy 100.00%\n",
      "Epoch   60/100 Cost: 0.202335 Accuracy 100.00%\n",
      "Epoch   70/100 Cost: 0.169252 Accuracy 100.00%\n",
      "Epoch   80/100 Cost: 0.150666 Accuracy 100.00%\n",
      "Epoch   90/100 Cost: 0.139571 Accuracy 100.00%\n",
      "Epoch  100/100 Cost: 0.130387 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습이 잘 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0227],\n",
       "        [0.1455],\n",
       "        [0.2654],\n",
       "        [0.8004],\n",
       "        [0.9511],\n",
       "        [0.9842]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.5797, 0.4135]], requires_grad=True), Parameter containing:\n",
      "tensor([-6.1706], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델을 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 2.757782 Accuracy 50.00%\n",
      "Epoch   10/100 Cost: 0.943425 Accuracy 66.67%\n",
      "Epoch   20/100 Cost: 0.588422 Accuracy 83.33%\n",
      "Epoch   30/100 Cost: 0.482159 Accuracy 83.33%\n",
      "Epoch   40/100 Cost: 0.396199 Accuracy 83.33%\n",
      "Epoch   50/100 Cost: 0.314984 Accuracy 83.33%\n",
      "Epoch   60/100 Cost: 0.241871 Accuracy 83.33%\n",
      "Epoch   70/100 Cost: 0.186650 Accuracy 100.00%\n",
      "Epoch   80/100 Cost: 0.157397 Accuracy 100.00%\n",
      "Epoch   90/100 Cost: 0.143995 Accuracy 100.00%\n",
      "Epoch  100/100 Cost: 0.134189 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "model = BinaryClassifier()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 100\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
    "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __소프트맥스 회귀__  \n",
    "\n",
    "#### 클래스가 여러개일때 사용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "y_one_hot = torch.zeros(8, 3) #Class가 0,1,2로 3개\n",
    "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "print(y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.scatter_와 torch.unsqueeze 함수를 활용하면 y를 one-hot encoding 할 수 있음.\n",
    "scatter 함수의 의미는 순서대로 dimension=1 에 해당하는 방향으로 y_train.unsqueeze(1)의 값들을 흩뿌려주는데, 1 이라는 숫자를 사용하여 흩뿌리라는 의미이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scatter](./scatter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # 가설\n",
    "    hypothesis = F.softmax(x_train.matmul(W) + b, dim=1) \n",
    "\n",
    "    # 비용 함수\n",
    "    cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산\n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 라이브러리 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.801172\n",
      "Epoch  100/1000 Cost: 0.720446\n",
      "Epoch  200/1000 Cost: 0.636338\n",
      "Epoch  300/1000 Cost: 0.578350\n",
      "Epoch  400/1000 Cost: 0.527740\n",
      "Epoch  500/1000 Cost: 0.480111\n",
      "Epoch  600/1000 Cost: 0.433820\n",
      "Epoch  700/1000 Cost: 0.388085\n",
      "Epoch  800/1000 Cost: 0.342558\n",
      "Epoch  900/1000 Cost: 0.297544\n",
      "Epoch 1000/1000 Cost: 0.256814\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(4, 3)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 클래스로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.565856\n",
      "Epoch  100/1000 Cost: 0.758088\n",
      "Epoch  200/1000 Cost: 0.666714\n",
      "Epoch  300/1000 Cost: 0.608195\n",
      "Epoch  400/1000 Cost: 0.557963\n",
      "Epoch  500/1000 Cost: 0.510913\n",
      "Epoch  600/1000 Cost: 0.465259\n",
      "Epoch  700/1000 Cost: 0.420179\n",
      "Epoch  800/1000 Cost: 0.375231\n",
      "Epoch  900/1000 Cost: 0.330270\n",
      "Epoch 1000/1000 Cost: 0.285943\n"
     ]
    }
   ],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3) # Output이 3!\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "model = SoftmaxClassifierModel()\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
