{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBYXHLi1Lq5pnDEILCn1U5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6408612a7d14395869ac83167fb6cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_587d840233a04f3197aa63ca40f10713"
            ],
            "layout": "IPY_MODEL_9634d5ecef8c48a1858aff9fa932bdea"
          }
        },
        "587d840233a04f3197aa63ca40f10713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_97622a352968418c844ad6876f391a8d",
            "width": ""
          }
        },
        "9634d5ecef8c48a1858aff9fa932bdea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97622a352968418c844ad6876f391a8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a6539a8e0b64f9c8e0030e8ba4e0f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e0a389450944a7dae46b593d007b9e2"
            ],
            "layout": "IPY_MODEL_29e448d4787040da8ea831f34449845c"
          }
        },
        "6e0a389450944a7dae46b593d007b9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_5aea0c9fe5834d45b25242dfd1323944",
            "width": ""
          }
        },
        "29e448d4787040da8ea831f34449845c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aea0c9fe5834d45b25242dfd1323944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08df6d98f34b42f9bfde86063fc018c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4fee0a75c9f420c8e756cc285c49a82"
            ],
            "layout": "IPY_MODEL_e9fe82ee9f6f4c9992b79aa79a32a93a"
          }
        },
        "e4fee0a75c9f420c8e756cc285c49a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "",
            "layout": "IPY_MODEL_fab8b92f6cdd4ddabd52dd9a9c99ec36",
            "width": ""
          }
        },
        "e9fe82ee9f6f4c9992b79aa79a32a93a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab8b92f6cdd4ddabd52dd9a9c99ec36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/impos0108/AI_basic_for_atmospheric_science/blob/main/ConvLSTM_with_movingMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E6NgXYleqlU5"
      },
      "outputs": [],
      "source": [
        "! wget -q https://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import io\n",
        "import imageio\n",
        "from ipywidgets import widgets, HBox\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "m2lgAA4JqpX6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data as Numpy Array\n",
        "MovingMNIST = np.load('mnist_test_seq.npy').transpose(1, 0, 2, 3)\n",
        "\n",
        "# Shuffle Data\n",
        "np.random.shuffle(MovingMNIST)\n",
        "\n",
        "# Train, Test, Validation splits\n",
        "train_data = MovingMNIST[:8000]\n",
        "val_data = MovingMNIST[8000:9000]\n",
        "test_data = MovingMNIST[9000:10000]\n",
        "\n",
        "def collate(batch):\n",
        "\n",
        "    # Add channel dim, scale pixels between 0 and 1, send to GPU\n",
        "    batch = torch.tensor(batch).unsqueeze(1)\n",
        "    batch = batch / 255.0\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    # Randomly pick 10 frames as input, 11th frame is target\n",
        "    rand = np.random.randint(10,20)\n",
        "    return batch[:,:,rand-10:rand], batch[:,:,rand]\n",
        "\n",
        "\n",
        "# Training Data Loader\n",
        "train_loader = DataLoader(train_data, shuffle=True,\n",
        "                        batch_size=16, collate_fn=collate)\n",
        "\n",
        "# Validation Data Loader\n",
        "val_loader = DataLoader(val_data, shuffle=True,\n",
        "                        batch_size=16, collate_fn=collate)"
      ],
      "metadata": {
        "id": "c838lsiEqs22"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch\n",
        "input, _ = next(iter(val_loader))\n",
        "\n",
        "# Reverse process before displaying\n",
        "input = input.cpu().numpy() * 255.0\n",
        "\n",
        "for video in input.squeeze(1)[:3]:          # Loop over videos\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif,video.astype(np.uint8),\"GIF\",fps=5)\n",
        "        display(HBox([widgets.Image(value=gif.getvalue())]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278,
          "referenced_widgets": [
            "d6408612a7d14395869ac83167fb6cb8",
            "587d840233a04f3197aa63ca40f10713",
            "9634d5ecef8c48a1858aff9fa932bdea",
            "97622a352968418c844ad6876f391a8d",
            "7a6539a8e0b64f9c8e0030e8ba4e0f8e",
            "6e0a389450944a7dae46b593d007b9e2",
            "29e448d4787040da8ea831f34449845c",
            "5aea0c9fe5834d45b25242dfd1323944",
            "08df6d98f34b42f9bfde86063fc018c6",
            "e4fee0a75c9f420c8e756cc285c49a82",
            "e9fe82ee9f6f4c9992b79aa79a32a93a",
            "fab8b92f6cdd4ddabd52dd9a9c99ec36"
          ]
        },
        "id": "9myEnw5XrMP6",
        "outputId": "e9b5156e-5f5e-4534-bcf8-f62e44e9ea61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-2c956a06bd01>:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  batch = torch.tensor(batch).unsqueeze(1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Image(value=b'GIF89a@\\x00@\\x00\\x86\\x00\\x00\\x00\\x00\\x00\\x02\\x02\\x02\\x03\\x03\\x03\\x05\\x05\\x05\\x08\\…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6408612a7d14395869ac83167fb6cb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Image(value=b'GIF89a@\\x00@\\x00\\x86\\x00\\x00\\x00\\x00\\x00\\x02\\x02\\x02\\x04\\x04\\x04\\x05\\x05\\x05\\x08\\…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a6539a8e0b64f9c8e0030e8ba4e0f8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Image(value=b'GIF89a@\\x00@\\x00\\x86\\x00\\x00\\x00\\x00\\x00\\x02\\x02\\x02\\x03\\x03\\x03\\x04\\x04\\x04\\x05\\…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08df6d98f34b42f9bfde86063fc018c6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels,\n",
        "    kernel_size, padding, activation, frame_size):\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        if activation == \"tanh\":\n",
        "            self.activation = torch.tanh\n",
        "        elif activation == \"relu\":\n",
        "            self.activation = torch.relu\n",
        "\n",
        "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=in_channels + out_channels,\n",
        "            out_channels=4 * out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=padding)\n",
        "\n",
        "        # Initialize weights for Hadamard Products\n",
        "        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
        "        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
        "        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
        "\n",
        "    def forward(self, X, H_prev, C_prev):\n",
        "\n",
        "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "        conv_output = self.conv(torch.cat([X, H_prev], dim=1))\n",
        "\n",
        "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
        "        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)\n",
        "\n",
        "        input_gate = torch.sigmoid(i_conv + self.W_ci * C_prev )\n",
        "        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_prev )\n",
        "\n",
        "        # Current Cell output\n",
        "        C = forget_gate*C_prev + input_gate * self.activation(C_conv)\n",
        "\n",
        "        output_gate = torch.sigmoid(o_conv + self.W_co * C )\n",
        "\n",
        "        # Current Hidden State\n",
        "        H = output_gate * self.activation(C)\n",
        "\n",
        "        return H, C"
      ],
      "metadata": {
        "id": "hLKiS42ernju"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels,\n",
        "    kernel_size, padding, activation, frame_size):\n",
        "\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # We will unroll this over time steps\n",
        "        self.convLSTMcell = ConvLSTMCell(in_channels, out_channels,\n",
        "        kernel_size, padding, activation, frame_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)\n",
        "\n",
        "        # Get the dimensions\n",
        "        batch_size, _, seq_len, height, width = X.size()\n",
        "\n",
        "        # Initialize output\n",
        "        output = torch.zeros(batch_size, self.out_channels, seq_len,\n",
        "        height, width, device=device)\n",
        "\n",
        "        # Initialize Hidden State\n",
        "        H = torch.zeros(batch_size, self.out_channels,\n",
        "        height, width, device=device)\n",
        "\n",
        "        # Initialize Cell Input\n",
        "        C = torch.zeros(batch_size,self.out_channels,\n",
        "        height, width, device=device)\n",
        "\n",
        "        # Unroll over time steps\n",
        "        for time_step in range(seq_len):\n",
        "\n",
        "            H, C = self.convLSTMcell(X[:,:,time_step], H, C)\n",
        "\n",
        "            output[:,:,time_step] = H\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "w9UE7n9SrpXy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, num_channels, num_kernels, kernel_size, padding,\n",
        "    activation, frame_size, num_layers):\n",
        "\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.sequential = nn.Sequential()\n",
        "\n",
        "        # Add First layer (Different in_channels than the rest)\n",
        "        self.sequential.add_module(\n",
        "            \"convlstm1\", ConvLSTM(\n",
        "                in_channels=num_channels, out_channels=num_kernels,\n",
        "                kernel_size=kernel_size, padding=padding,\n",
        "                activation=activation, frame_size=frame_size)\n",
        "        )\n",
        "\n",
        "        self.sequential.add_module(\n",
        "            \"batchnorm1\", nn.BatchNorm3d(num_features=num_kernels)\n",
        "        )\n",
        "\n",
        "        # Add rest of the layers\n",
        "        for l in range(2, num_layers+1):\n",
        "\n",
        "            self.sequential.add_module(\n",
        "                f\"convlstm{l}\", ConvLSTM(\n",
        "                    in_channels=num_kernels, out_channels=num_kernels,\n",
        "                    kernel_size=kernel_size, padding=padding,\n",
        "                    activation=activation, frame_size=frame_size)\n",
        "                )\n",
        "\n",
        "            self.sequential.add_module(\n",
        "                f\"batchnorm{l}\", nn.BatchNorm3d(num_features=num_kernels)\n",
        "                )\n",
        "\n",
        "        # Add Convolutional Layer to predict output frame\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=num_kernels, out_channels=num_channels,\n",
        "            kernel_size=kernel_size, padding=padding)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        # Forward propagation through all the layers\n",
        "        output = self.sequential(X)\n",
        "\n",
        "        # Return only the last output frame\n",
        "        output = self.conv(output[:,:,-1])\n",
        "\n",
        "        return nn.Sigmoid()(output)"
      ],
      "metadata": {
        "id": "hEdHYjDQrdGY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The input video frames are grayscale, thus single channel\n",
        "model = Seq2Seq(num_channels=1, num_kernels=64,\n",
        "kernel_size=(3, 3), padding=(1, 1), activation=\"relu\",\n",
        "frame_size=(64, 64), num_layers=3).to(device)\n",
        "\n",
        "optim = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Binary Cross Entropy, target pixel values either 0 or 1\n",
        "criterion = nn.BCELoss(reduction='sum')"
      ],
      "metadata": {
        "id": "yajrw2wXrtzQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    for batch_num, (input, target) in enumerate(train_loader, 1):\n",
        "        output = model(input)\n",
        "        loss = criterion(output.flatten(), target.flatten())\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    val_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for input, target in val_loader:\n",
        "            output = model(input)\n",
        "            loss = criterion(output.flatten(), target.flatten())\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(\"Epoch:{} Training Loss:{:.2f} Validation Loss:{:.2f}\\n\".format(\n",
        "        epoch, train_loss, val_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO4SJvVZrxWl",
        "outputId": "afa7eda7-ced3-4ca6-9f6a-48609fec3d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 Training Loss:1808.28 Validation Loss:930.28\n",
            "\n",
            "Epoch:2 Training Loss:844.83 Validation Loss:827.01\n",
            "\n",
            "Epoch:3 Training Loss:823.65 Validation Loss:824.61\n",
            "\n",
            "Epoch:4 Training Loss:822.75 Validation Loss:826.34\n",
            "\n",
            "Epoch:5 Training Loss:823.89 Validation Loss:825.39\n",
            "\n",
            "Epoch:6 Training Loss:822.10 Validation Loss:825.88\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_test(batch):\n",
        "\n",
        "    # Last 10 frames are target\n",
        "    target = np.array(batch)[:,10:]\n",
        "\n",
        "    # Add channel dim, scale pixels between 0 and 1, send to GPU\n",
        "    batch = torch.tensor(batch).unsqueeze(1)\n",
        "    batch = batch / 255.0\n",
        "    batch = batch.to(device)\n",
        "    return batch, target\n",
        "\n",
        "# Test Data Loader\n",
        "test_loader = DataLoader(test_data,shuffle=True,\n",
        "                         batch_size=3, collate_fn=collate_test)\n",
        "\n",
        "# Get a batch\n",
        "batch, target = next(iter(test_loader))\n",
        "\n",
        "# Initialize output sequence\n",
        "output = np.zeros(target.shape, dtype=np.uint8)\n",
        "\n",
        "# Loop over timesteps\n",
        "for timestep in range(target.shape[1]):\n",
        "  input = batch[:,:,timestep:timestep+10]\n",
        "  output[:,timestep]=(model(input).squeeze(1).cpu()>0.5)*255.0"
      ],
      "metadata": {
        "id": "qCltypuZr0Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tgt, out in zip(target, output):       # Loop over samples\n",
        "\n",
        "    # Write target video as gif\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif, tgt, \"GIF\", fps = 5)\n",
        "        target_gif = gif.getvalue()\n",
        "\n",
        "    # Write output video as gif\n",
        "    with io.BytesIO() as gif:\n",
        "        imageio.mimsave(gif, out, \"GIF\", fps = 5)\n",
        "        output_gif = gif.getvalue()\n",
        "\n",
        "    display(HBox([widgets.Image(value=target_gif),\n",
        "                  widgets.Image(value=output_gif)]))"
      ],
      "metadata": {
        "id": "4kJ0AGU76DS4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}